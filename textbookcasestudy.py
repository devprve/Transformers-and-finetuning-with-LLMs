# -*- coding: utf-8 -*-
"""TextbookCaseStudy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eTIat6Psq3xLgJDI8g1qcB1K0JEiNi0G
"""

!pip install transformers torch

textbook_content = """
Photosynthesis is a process used by plants, algae, and some bacteria to convert light energy, usually from the sun, into chemical energy in the form of glucose or other sugars. These organisms are known as photoautotrophs. The process takes place in the chloroplasts, using chlorophyll, the green pigment in plants.

There are two main stages of photosynthesis: the light-dependent reactions and the light-independent reactions, often referred to as the Calvin cycle. In the light-dependent reactions, energy from sunlight is absorbed by chlorophyll and converted into chemical energy in the form of ATP and NADPH. The light-independent reactions, on the other hand, use the ATP and NADPH to convert carbon dioxide from the atmosphere into glucose.

Water is essential for photosynthesis. It is split into oxygen, which is released into the atmosphere, and hydrogen, which is used in the light-independent reactions to produce glucose.
"""

with open('textbook.txt', 'w') as f:
    f.write(textbook_content)

!pip install accelerate -U

!pip install transformers[torch] -U

from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, TrainingArguments, Trainer

# Load small GPT-2 model and tokenizer
model_name = "gpt2-medium"
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)

# Prepare dataset
train_dataset = TextDataset(tokenizer=tokenizer, file_path="textbook.txt", block_size=128)
data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

# Training setup
training_args = TrainingArguments(
    per_device_train_batch_size=8,
    num_train_epochs=1,
    logging_dir='./logs',
    logging_steps=10,
    do_train=True,
    output_dir="./model",
)

trainer = Trainer(
    model=model,
    args=training_args,
    data_collator=data_collator,
    train_dataset=train_dataset,
)

# Train the model
trainer.train()

def ask_question(question, model, tokenizer):
    input_text = tokenizer.encode(question, return_tensors="pt")
    output = model.generate(input_text, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, top_k=50, temperature=0.7)
    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)
    return decoded_output

question = "What is the role of water in photosynthesis?"
answer = ask_question(question, model, tokenizer)
print(answer)