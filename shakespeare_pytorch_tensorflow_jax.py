# -*- coding: utf-8 -*-
"""Shakespeare-PyTorch-TensorFlow-Jax.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tfJFN-1sOGzcvX11UlYWUqTAyx928ds8
"""

import torch
import torch.nn as nn

class NanoGPT(nn.Module):
    def __init__(self, vocab_size, hidden_size, num_layers):
        super(NanoGPT, self).__init__()

        self.embedding = nn.Embedding(vocab_size, hidden_size)
        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=hidden_size, nhead=8), num_layers=num_layers)
        self.linear = nn.Linear(hidden_size, vocab_size)

    def forward(self, x):
        x = self.embedding(x)
        x = self.transformer(x)
        x = self.linear(x)
        return x

# Create a NanoGPT model with a vocabulary size of 10000, hidden size of 256, and 6 layers
model = NanoGPT(vocab_size=10000, hidden_size=256, num_layers=6)

# Train the model on a dataset of text
optimizer = torch.optim.Adam(model.parameters())
loss_fn = nn.CrossEntropyLoss()

for epoch in range(10):
    for batch in train_data:
        x, y = batch
        optimizer.zero_grad()
        outputs = model(x)
        loss = loss_fn(outputs, y)
        loss.backward()
        optimizer.step()

# Save the trained model
torch.save(model.state_dict(), 'nanogpt.pt')

import tensorflow as tf

class NanoGPT(tf.keras.Model):
    def __init__(self, vocab_size, hidden_size, num_layers):
        super(NanoGPT, self).__init__()

        self.embedding = tf.keras.layers.Embedding(vocab_size, hidden_size)
        self.transformer = tf.keras.layers.TransformerEncoder(tf.keras.layers.TransformerEncoderLayer(d_model=hidden_size, nhead=8), num_layers=num_layers)
        self.linear = tf.keras.layers.Dense(vocab_size)

    def call(self, x):
        x = self.embedding(x)
        x = self.transformer(x)
        x = self.linear(x)
        return x

# Create a NanoGPT model with a vocabulary size of 10000, hidden size of 256, and 6 layers
model = NanoGPT(vocab_size=10000, hidden_size=256, num_layers=6)

# Train the model on a dataset of text
optimizer = tf.keras.optimizers.Adam()
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

for epoch in range(10):
    for batch in train_data:
        x, y = batch
        with tf.GradientTape() as tape:
            outputs = model(x)
            loss = loss_fn(y, outputs)
        grads = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(grads, model.trainable_variables))

# Save the trained model
model.save_weights('nanogpt.h5')

import jax
import jax.nn as jnn

class NanoGPT(jax.nn.Module):
    def __init__(self, vocab_size, hidden_size, num_layers):
        super(NanoGPT, self).__init__()

        self.embedding = jnn.Embedding(vocab_size, hidden_size)
        self.transformer = jax.lax.while_loop(
            lambda i, x: i < num_layers,
            lambda i, x: (i + 1, jnn.TransformerEncoderLayer(hidden_size, nhead=8)(x)),
            (0, self.embedding(x))
        )
        self.linear = jnn.Dense(vocab_size)

    def call(self, x):
        x = self.transformer(x)
        x = self.linear(x)
        return x

# Create a NanoGPT model with a vocabulary size of 10000, hidden size of 256, and 6 layers
model = NanoGPT(vocab_size=10000, hidden_size=256, num_layers=6)

# Train the model on a dataset of text
optimizer = jnp.optimizers.Adam()
loss_fn = jax.nn.cross_entropy_loss

for epoch in range(10):
    for batch in train_data:
        x, y = batch
        with jnp.gradient_tape() as tape:
            outputs = model(x)
            loss = loss_fn(outputs, y)
        grads = tape.gradient(loss, model.parameters())
        optimizer.update(grads, model.parameters())

# Save the trained model
jax.tree_map(jax.nn.save, 'nanogpt.jax', model.parameters())

import jax
import jax.nn as jnn

# Load the NanoGPT model
model = jax.tree_map(jax.nn.load, 'nanogpt.jax')

# Train the model on the training data
optimizer = jnp.optimizers.Adam()
loss_fn = jax.nn.cross_entropy_loss

for epoch in range(10):
    for batch in train_data:
        x, y = batch
        with jnp.gradient_tape() as tape:
            outputs = model(x)
            loss = loss_fn(outputs, y)
        grads = tape.gradient(loss, model.parameters())
        optimizer.update(grads, model.parameters())

# Save the trained model
jax.tree_map(jax.nn.save, 'nanogpt.jax', model.parameters())

import jax
import jax.nn as jnn

# Load the trained NanoGPT model
model = jax.tree_map(jax.nn.load, 'nanogpt.jax')

# Generate text from the model
prompt = 'Once upon a time, there was a beautiful princess...'
max_len = 100

generated_text = ''
for i in range(max_len):
    token_id = model(generated_text)[:, i].argmax()
    token = jax.lax.dynamic_index_in_dim(vocab, token_id, axis=-1)
    generated_text += token + ' '

print(generated_text)